{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1049c62f-ef8f-452c-8068-87c6229bf463",
   "metadata": {},
   "source": [
    "# **DQN Autonomous self-driving car**\n",
    "\n",
    "## **Import Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7fa6d5-9cf5-4991-b366-692d73f78bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.8.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import carla\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pygame\n",
    "from collections import deque\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8fba65-8746-4e85-815c-199935e3811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(image, dim_x=128, dim_y=128):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    array = array[:, :, ::-1]\n",
    "\n",
    "    # scale_percent = 25\n",
    "    # width = int(array.shape[1] * scale_percent/100)\n",
    "    # height = int(array.shape[0] * scale_percent/100)\n",
    "\n",
    "    # dim = (width, height)\n",
    "    dim = (dim_x, dim_y)  # set same dim for now\n",
    "    resized_img = cv2.resize(array, dim, interpolation=cv2.INTER_AREA)\n",
    "    img_gray = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "    scaledImg = img_gray/255.\n",
    "\n",
    "    # normalize\n",
    "    mean, std = 0.5, 0.5\n",
    "    normalizedImg = (scaledImg - mean) / std\n",
    "\n",
    "    return normalizedImg\n",
    "\n",
    "def draw_image(surface, image, blend=False):\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array = np.reshape(array, (image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    array = array[:, :, ::-1]\n",
    "    image_surface = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n",
    "    if blend:\n",
    "        image_surface.set_alpha(100)\n",
    "    surface.blit(image_surface, (0, 0))\n",
    "\n",
    "def get_font():\n",
    "    fonts = [x for x in pygame.font.get_fonts()]\n",
    "    default_font = 'ubuntumono'\n",
    "    font = default_font if default_font in fonts else fonts[0]\n",
    "    font = pygame.font.match_font(font)\n",
    "    return pygame.font.Font(font, 14)\n",
    "\n",
    "def should_quit():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            return True\n",
    "        elif event.type == pygame.KEYUP:\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def get_speed(vehicle):\n",
    "    \"\"\"\n",
    "    Compute speed of a vehicle in Km/h.\n",
    "        :param vehicle: the vehicle for which speed is calculated\n",
    "        :return: speed as a float in Km/h\n",
    "    \"\"\"\n",
    "    vel = vehicle.get_velocity()\n",
    "\n",
    "    return 3.6 * math.sqrt(vel.x ** 2 + vel.y ** 2 + vel.z ** 2)\n",
    "\n",
    "def correct_yaw(x):\n",
    "    return(((x%360) + 360) % 360)\n",
    "\n",
    "def create_folders(folder_names):\n",
    "    for directory in folder_names:\n",
    "        if not os.path.exists(directory):\n",
    "                # If it doesn't exist, create it\n",
    "                os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce1ac5-7fa1-491a-8cef-a693aa1e638a",
   "metadata": {},
   "source": [
    "## **Create PID Controller**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4841b7a7-c6ed-4414-940f-82f87d6e2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIDLongitudinalController():\n",
    "    \"\"\"\n",
    "    PIDLongitudinalController implements longitudinal control using a PID.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vehicle, max_throttle=0.75, max_brake=0.3, K_P=1.0, K_I=0.0, K_D=0.0, dt=0.03):\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "            :param vehicle: actor to apply to local planner logic onto\n",
    "            :param K_P: Proportional term\n",
    "            :param K_D: Differential term\n",
    "            :param K_I: Integral term\n",
    "            :param dt: time differential in seconds\n",
    "        \"\"\"\n",
    "        self._vehicle = vehicle\n",
    "        self.max_throttle = max_throttle\n",
    "        self.max_brake = max_brake\n",
    "        self._k_p = K_P\n",
    "        self._k_i = K_I\n",
    "        self._k_d = K_D\n",
    "        self._dt = dt\n",
    "        self._error_buffer = deque(maxlen=10)\n",
    "\n",
    "    def run_step(self, target_speed, debug=False):\n",
    "        \"\"\"\n",
    "        Execute one step of longitudinal control to reach a given target speed.\n",
    "            :param target_speed: target speed in Km/h\n",
    "            :param debug: boolean for debugging\n",
    "            :return: throttle control\n",
    "        \"\"\"\n",
    "        current_speed = get_speed(self._vehicle)\n",
    "\n",
    "        if debug:\n",
    "            print('Current speed = {}'.format(current_speed))\n",
    "\n",
    "        acceleration = self._pid_control(target_speed, current_speed)\n",
    "        control = carla.VehicleControl()\n",
    "        if acceleration >= 0.0:\n",
    "            control.throttle = min(acceleration, self.max_throttle)\n",
    "            control.brake = 0.0\n",
    "        else:\n",
    "            control.throttle = 0.0\n",
    "            control.brake = min(abs(acceleration), self.max_brake)\n",
    "        return control\n",
    "\n",
    "    def _pid_control(self, target_speed, current_speed):\n",
    "        \"\"\"\n",
    "        Estimate the throttle/brake of the vehicle based on the PID equations\n",
    "            :param target_speed:  target speed in Km/h\n",
    "            :param current_speed: current speed of the vehicle in Km/h\n",
    "            :return: throttle/brake control\n",
    "        \"\"\"\n",
    "\n",
    "        error = target_speed - current_speed\n",
    "        self._error_buffer.append(error)\n",
    "\n",
    "        if len(self._error_buffer) >= 2:\n",
    "            _de = (self._error_buffer[-1] - self._error_buffer[-2]) / self._dt\n",
    "            _ie = sum(self._error_buffer) * self._dt\n",
    "        else:\n",
    "            _de = 0.0\n",
    "            _ie = 0.0\n",
    "\n",
    "        return np.clip((self._k_p * error) + (self._k_d * _de) + (self._k_i * _ie), -1.0, 1.0)\n",
    "\n",
    "    def change_parameters(self, K_P, K_I, K_D, dt):\n",
    "        \"\"\"Changes the PID parameters\"\"\"\n",
    "        self._k_p = K_P\n",
    "        self._k_i = K_I\n",
    "        self._k_d = K_D\n",
    "        self._dt = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bdd94-8074-4465-9a8a-0c1a73be6be1",
   "metadata": {},
   "source": [
    "## **Create Sync Mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285b6d30-c288-457d-98dd-a0b2b95cc631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "    Context manager to synchronize output from different sensors. Synchronous\n",
    "    mode is enabled as long as we are inside this context\n",
    "\n",
    "        with CarlaSyncMode(world, sensors) as sync_mode:\n",
    "            while True:\n",
    "                data = sync_mode.tick(timeout=1.0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, world, *sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 20)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "        self.collisions = []\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        try:\n",
    "            self.frame = self.world.tick()\n",
    "            data = [self._retrieve_data(q, timeout) for q in self._queues[:-1]]\n",
    "            # collision sensor is the last element in the queue\n",
    "            collision = self._detect_collision(self._queues[-1])\n",
    "            \n",
    "            assert all(x.frame == self.frame for x in data)\n",
    "\n",
    "            return data + [collision]\n",
    "        except queue.Empty:\n",
    "            print(\"empty queue\")\n",
    "            return None, None, None\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data\n",
    "    \n",
    "    def _detect_collision(self, sensor):\n",
    "        # This collision is not fully aligned with other sensors, fix later\n",
    "        try:\n",
    "            data = sensor.get(block=False)\n",
    "            return data\n",
    "        except queue.Empty:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59039e-ee41-4444-b43f-ce067c18d03d",
   "metadata": {},
   "source": [
    "## **Create Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e68a90-7b30-43bf-9151-65900821a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv(object):\n",
    "    def __init__(self, \n",
    "        visuals=True,\n",
    "        target_speed = 30,\n",
    "        max_iter = 4000,\n",
    "        start_buffer = 10,\n",
    "        train_freq = 1,\n",
    "        save_freq = 200,\n",
    "        start_ep = 0,\n",
    "        max_dist_from_waypoint = 20\n",
    "    ) -> None:\n",
    "        self.visuals = visuals\n",
    "        if self.visuals:\n",
    "            self._initiate_visuals()\n",
    "\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(10.0)\n",
    "\n",
    "        self.world = self.client.load_world('Town04_Opt')\n",
    "        self.world.unload_map_layer(carla.MapLayer.Decals)\n",
    "        self.world.unload_map_layer(carla.MapLayer.Foliage)\n",
    "        self.world.unload_map_layer(carla.MapLayer.ParkedVehicles)\n",
    "        self.world.unload_map_layer(carla.MapLayer.Particles)\n",
    "        self.world.unload_map_layer(carla.MapLayer.Props)\n",
    "        self.world.unload_map_layer(carla.MapLayer.StreetLights)\n",
    "        \n",
    "\n",
    "        self.spawn_points = self.world.get_map().get_spawn_points()\n",
    "\n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        self.vehicle_blueprint = self.blueprint_library.find('vehicle.mini.cooper_s_2021')\n",
    "\n",
    "        # input these later on as arguments\n",
    "        self.global_t = 0 # global timestep\n",
    "        self.target_speed = target_speed # km/h \n",
    "        self.max_iter = max_iter\n",
    "        self.start_buffer = start_buffer\n",
    "        self.train_freq = train_freq\n",
    "        self.save_freq = save_freq\n",
    "        self.start_ep = start_ep\n",
    "\n",
    "        self.max_dist_from_waypoint = max_dist_from_waypoint\n",
    "        self.start_train = self.start_ep + self.start_buffer\n",
    "        \n",
    "        self.total_rewards = 0\n",
    "        self.average_rewards_list = []\n",
    "    \n",
    "    def _initiate_visuals(self):\n",
    "        pygame.init()\n",
    "\n",
    "        self.display = pygame.display.set_mode(\n",
    "            (800, 600),\n",
    "            pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "        self.font = get_font()\n",
    "        self.clock = pygame.time.Clock()\n",
    "    \n",
    "    def create_actors(self):\n",
    "        self.actor_list = []\n",
    "        # spawn vehicle at random location\n",
    "        self.vehicle = self.world.spawn_actor(self.vehicle_blueprint, random.choice(self.spawn_points))\n",
    "        # vehicle.set_autopilot(True)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "\n",
    "        self.camera_rgb = self.world.spawn_actor(\n",
    "            self.blueprint_library.find('sensor.camera.rgb'),\n",
    "            carla.Transform(carla.Location(x=1.5, z=2.4), carla.Rotation(pitch=-15)),\n",
    "            attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.camera_rgb)\n",
    "\n",
    "        self.camera_rgb_vis = self.world.spawn_actor(\n",
    "            self.blueprint_library.find('sensor.camera.rgb'),\n",
    "            carla.Transform(carla.Location(x=-5.5, z=2.8), carla.Rotation(pitch=-15)),\n",
    "            attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.camera_rgb_vis)\n",
    "\n",
    "        self.collision_sensor = self.world.spawn_actor(\n",
    "            self.blueprint_library.find('sensor.other.collision'),\n",
    "            carla.Transform(),\n",
    "            attach_to=self.vehicle\n",
    "        )\n",
    "        self.actor_list.append(self.collision_sensor)\n",
    "\n",
    "        self.speed_controller = PIDLongitudinalController(self.vehicle)\n",
    "    \n",
    "    def reset(self):\n",
    "        for actor in self.actor_list:\n",
    "            actor.destroy()\n",
    "    \n",
    "    def generate_episode(self, model, replay_buffer, ep, action_map=None, eval=True):\n",
    "        with CarlaSyncMode(self.world, self.camera_rgb, self.camera_rgb_vis, self.collision_sensor, fps=30) as sync_mode:\n",
    "            counter = 0\n",
    "\n",
    "            snapshot, image_rgb, image_rgb_vis, collision = sync_mode.tick(timeout=2.0)\n",
    "\n",
    "            # destroy if there is no data\n",
    "            if snapshot is None or image_rgb is None:\n",
    "                print(\"No data, skipping episode\")\n",
    "                self.reset()\n",
    "                return None\n",
    "\n",
    "            image = process_img(image_rgb)\n",
    "            next_state = image \n",
    "\n",
    "            while True:\n",
    "                if self.visuals:\n",
    "                    if should_quit():\n",
    "                        return\n",
    "                    self.clock.tick_busy_loop(30)\n",
    "\n",
    "                vehicle_location = self.vehicle.get_location()\n",
    "\n",
    "                waypoint = self.world.get_map().get_waypoint(vehicle_location, project_to_road=True, \n",
    "                    lane_type=carla.LaneType.Driving)\n",
    "                \n",
    "                speed = get_speed(self.vehicle)\n",
    "\n",
    "                # Advance the simulation and wait for the data.\n",
    "                state = next_state\n",
    "\n",
    "                counter += 1\n",
    "                self.global_t += 1\n",
    "\n",
    "\n",
    "                action = model.select_action(state, eval=eval)\n",
    "                steer = action\n",
    "                if action_map is not None:\n",
    "                    steer = action_map[action]\n",
    "\n",
    "                control = self.speed_controller.run_step(self.target_speed)\n",
    "                control.steer = steer\n",
    "                self.vehicle.apply_control(control)\n",
    "\n",
    "                fps = round(1.0 / snapshot.timestamp.delta_seconds)\n",
    "\n",
    "                snapshot, image_rgb, image_rgb_vis, collision = sync_mode.tick(timeout=2.0)\n",
    "\n",
    "                cos_yaw_diff, dist, collision = get_reward_comp(self.vehicle, waypoint, collision)\n",
    "                reward = reward_value(cos_yaw_diff, dist, collision)\n",
    "\n",
    "                if snapshot is None or image_rgb is None:\n",
    "                    print(\"Process ended here\")\n",
    "                    break\n",
    "\n",
    "                image = process_img(image_rgb)\n",
    "\n",
    "                done = 1 if collision else 0\n",
    "\n",
    "                self.total_rewards += reward\n",
    "\n",
    "                next_state = image\n",
    "\n",
    "                replay_buffer.add(state, action, next_state, reward, done)\n",
    "\n",
    "                if not eval:\n",
    "                    if ep > self.start_train and (self.global_t % self.train_freq) == 0:\n",
    "                        model.train(replay_buffer)\n",
    "\n",
    "                # Draw the display.\n",
    "                if self.visuals:\n",
    "                    draw_image(self.display, image_rgb_vis)\n",
    "                    self.display.blit(\n",
    "                        self.font.render('% 5d FPS (real)' % self.clock.get_fps(), True, (255, 255, 255)),\n",
    "                        (8, 10))\n",
    "                    self.display.blit(\n",
    "                        self.font.render('% 5d FPS (simulated)' % fps, True, (255, 255, 255)),\n",
    "                        (8, 28))\n",
    "                    pygame.display.flip()\n",
    "\n",
    "                if collision == 1 or counter >= self.max_iter or dist > self.max_dist_from_waypoint:\n",
    "                    print(\"Episode {} processed\".format(ep), counter)\n",
    "                    break\n",
    "            \n",
    "            if ep % self.save_freq == 0 and ep > 0:\n",
    "                self.save(model, ep)\n",
    "\n",
    "    def save(self, model, ep):\n",
    "        if ep % self.save_freq == 0 and ep > self.start_ep:\n",
    "            avg_reward = self.total_rewards/self.save_freq\n",
    "            self.average_rewards_list.append(avg_reward)\n",
    "            self.total_rewards = 0\n",
    "\n",
    "            model.save('weights/model_ep_{}'.format(ep))\n",
    "\n",
    "            print(\"Saved model with average reward =\", avg_reward)\n",
    "    \n",
    "    def quit(self):\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0df918-7bd8-47c0-b42d-d973566d68a4",
   "metadata": {},
   "source": [
    "## **Create Model**\n",
    "\n",
    "create ConvNet and DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe93dc9e-71f7-4305-a382-1c429fe576ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, dim, in_channels, num_actions) -> None:\n",
    "        super(ConvNet, self).__init__()\n",
    "        # conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, 8, 4)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*8*8, 256)\n",
    "        self.fc1_bn = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "        self.fc2_bn = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(32, num_actions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x.reshape(-1, 64*8*8))))\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94330c1f-6c48-4520-b495-58a262ca1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions,\n",
    "        state_dim, #?\n",
    "        in_channels,\n",
    "        device,\n",
    "        discount=0.9,\n",
    "        optimizer=\"Adam\",\n",
    "        optimizer_parameters={'lr':0.01},\n",
    "        target_update_frequency=1e4,\n",
    "        initial_eps = 1,\n",
    "        end_eps = 0.05,\n",
    "        eps_decay_period = 25e4,\n",
    "        eval_eps=0.001\n",
    "    ) -> None:\n",
    "        self.device = device\n",
    "\n",
    "        self.Q = ConvNet(state_dim, in_channels, num_actions).to(self.device)\n",
    "        self.Q_target = copy.deepcopy(self.Q)  # copy target network\n",
    "        self.Q_optimizer = getattr(torch.optim, optimizer)(self.Q.parameters(), \n",
    "        **optimizer_parameters)\n",
    "\n",
    "        self.discount = discount\n",
    "\n",
    "        self.target_update_frequency = target_update_frequency\n",
    " \n",
    "        # epsilon decay\n",
    "        self.initial_eps = initial_eps\n",
    "        self.end_eps = end_eps\n",
    "        self.slope = (self.end_eps - self.initial_eps) / eps_decay_period\n",
    "\n",
    "        self.state_shape = (-1,) + state_dim\n",
    "        self.eval_eps = eval_eps\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.iterations = 0\n",
    "\n",
    "    def select_action(self, state, eval=False):\n",
    "        eps = self.eval_eps if eval \\\n",
    "        else max(self.slope * self.iterations + self.initial_eps, self.end_eps)\n",
    "        self.current_eps = eps\n",
    "\n",
    "        # Select action according to policy with probability (1-eps)\n",
    "        # otherwise, select random action\n",
    "        if np.random.uniform(0,1) > eps:\n",
    "            self.Q.eval()\n",
    "            with torch.no_grad():\n",
    "                # without batch norm, remove the unsqueeze\n",
    "                state = torch.FloatTensor(state).reshape(self.state_shape).unsqueeze(0).to(self.device)\n",
    "                return int(self.Q(state).argmax(1))\n",
    "        else:\n",
    "            return np.random.randint(self.num_actions)\n",
    "\n",
    "    def train(self, replay_buffer):\n",
    "        self.Q.train()\n",
    "        # Sample mininbatch from replay buffer\n",
    "        state, action, next_state, reward, done = replay_buffer.sample()\n",
    "\n",
    "        # Compute the target Q value\n",
    "        with torch.no_grad():\n",
    "            target_Q = reward + (1-done) * self.discount * self.Q_target(next_state).max(1, keepdim=True)[0]\n",
    "\n",
    "        # Get current Q estimate\n",
    "        # torch gather just selects action values from Q(state) using the action tensor as an index\n",
    "        current_Q = self.Q(state).gather(1, action)\n",
    "\n",
    "        # Compute Q loss\n",
    "        Q_loss = F.smooth_l1_loss(current_Q, target_Q)\n",
    "\n",
    "        # Optimize the Q\n",
    "        self.Q_optimizer.zero_grad()\n",
    "        Q_loss.backward()\n",
    "        self.Q_optimizer.step()\n",
    "\n",
    "        # Update target network by full copy every X iterations.\n",
    "        self.iterations += 1\n",
    "        self.copy_target_update()\n",
    "    \n",
    "    def copy_target_update(self):\n",
    "        if self.iterations % self.target_update_frequency == 0:\n",
    "            print('target network updated')\n",
    "            print('current epsilon', self.current_eps)\n",
    "            self.Q_target.load_state_dict(self.Q.state_dict())\n",
    "\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.Q.state_dict(), filename + \"_Q\")\n",
    "        torch.save(self.Q_optimizer.state_dict(), filename + \"_optimizer\")\n",
    "\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.Q.load_state_dict(torch.load(filename + \"_Q\"))\n",
    "        self.Q_target = copy.deepcopy(self.Q)\n",
    "        self.Q_optimizer.load_state_dict(torch.load(filename + \"_optimizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0adb58-424e-4643-b80e-40cedc4e6db3",
   "metadata": {},
   "source": [
    "## **Create Replay Buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dade04ab-10aa-4cc6-8adb-30677682277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, state_dim, batch_size, buffer_size, device) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.max_size = int(buffer_size)\n",
    "        self.device = device\n",
    "\n",
    "        self.ptr = 0\n",
    "        self.crt_size = 0\n",
    "\n",
    "        self.state = np.zeros((self.max_size,) + state_dim)\n",
    "        self.action = np.zeros((self.max_size, 1))\n",
    "        self.next_state = np.array(self.state)\n",
    "        self.reward = np.zeros((self.max_size, 1))\n",
    "        self.done = np.zeros((self.max_size, 1))\n",
    "\n",
    "    def add(self, state, action, next_state, reward, done):\n",
    "        self.state[self.ptr] = state\n",
    "        self.action[self.ptr] = action\n",
    "        self.next_state[self.ptr] = next_state\n",
    "        self.reward[self.ptr] = reward\n",
    "        self.done[self.ptr] = done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.crt_size = min(self.crt_size + 1, self.max_size)\n",
    "\n",
    "    def sample(self):\n",
    "        ind = np.random.randint(0, self.crt_size, size=self.batch_size)\n",
    "        return (\n",
    "            torch.FloatTensor(self.state[ind]).unsqueeze(1).to(self.device),\n",
    "            torch.LongTensor(self.action[ind]).to(self.device),\n",
    "            torch.FloatTensor(self.next_state[ind]).unsqueeze(1).to(self.device),\n",
    "            torch.FloatTensor(self.reward[ind]).to(self.device),\n",
    "            torch.FloatTensor(self.done[ind]).to(self.device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155ccd6-e0d3-415b-b1e5-3f69b97ed262",
   "metadata": {},
   "source": [
    "## **Reward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2432ce7a-7284-46a0-a16d-d1bcb9b6caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_comp(vehicle, waypoint, collision):\n",
    "    vehicle_location = vehicle.get_location()\n",
    "    x_wp = waypoint.transform.location.x\n",
    "    y_wp = waypoint.transform.location.y\n",
    "\n",
    "    x_vh = vehicle_location.x\n",
    "    y_vh = vehicle_location.y\n",
    "\n",
    "    wp_array = np.array([x_wp, y_wp])\n",
    "    vh_array = np.array([x_vh, y_vh])\n",
    "\n",
    "    dist = np.linalg.norm(wp_array - vh_array)\n",
    "\n",
    "    vh_yaw = correct_yaw(vehicle.get_transform().rotation.yaw)\n",
    "    wp_yaw = correct_yaw(waypoint.transform.rotation.yaw)\n",
    "    cos_yaw_diff = np.cos((vh_yaw - wp_yaw)*np.pi/180.)\n",
    "\n",
    "    collision = 0 if collision is None else 1\n",
    "    \n",
    "    return cos_yaw_diff, dist, collision\n",
    "\n",
    "def reward_value(cos_yaw_diff, dist, collision, lambda_1=1, lambda_2=1, lambda_3=5):\n",
    "    reward = (lambda_1 * cos_yaw_diff) - (lambda_2 * dist) - (lambda_3 * collision)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f72b4a-f0bc-47c7-8e1a-6cf61e5ff7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn action values\n",
    "action_values = [-0.75, -0.5, -0.25, -0.15, -0.1, -0.05, 0,\n",
    "                0.05, 0.1, 0.15, 0.25, 0.5, 0.75]\n",
    "action_map = {i:x for i, x in enumerate(action_values)}\n",
    "\n",
    "env_params = {\n",
    "    'target_speed' :30 , \n",
    "    'max_iter': 4000,\n",
    "    'start_buffer': 10,\n",
    "    'train_freq': 1,\n",
    "    'save_freq': 1000,\n",
    "    'start_ep': 0,\n",
    "    'max_dist_from_waypoint': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d76c7a-ddb1-4f3e-94df-d660267b96e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 processed 140\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    buffer_size = 1e4\n",
    "    batch_size = 32\n",
    "    episodes = 10000\n",
    "    state_dim = (128, 128)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_actions = len(action_map)\n",
    "    in_channels = 1\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(state_dim, batch_size, buffer_size, device)\n",
    "    model = DQN(num_actions, state_dim, in_channels, device)\n",
    "\n",
    "    # this only works if you have a model in your weights folder. Replace this by that file\n",
    "    # model.load('weights/model_ep_4400')\n",
    "\n",
    "    # set to True if you want to run with pygame\n",
    "    env = CarEnv(visuals=True, **env_params)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        env.create_actors()\n",
    "        env.generate_episode(model, replay_buffer, ep, action_map, eval=True)\n",
    "        env.reset()\n",
    "finally:\n",
    "    env.reset()\n",
    "    env.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9ea75-64b3-42ec-a41f-ad8abf8f4543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CARLA",
   "language": "python",
   "name": "carla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
